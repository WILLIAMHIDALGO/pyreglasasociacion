{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From http://aimotion.blogspot.com.es/2013/01/machine-learning-and-data-mining.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to build frequent itemsets?\n",
    "\n",
    "There is an algorithm to generate frequent itemsets in an efficient way: Apriori\n",
    "\n",
    "## Apriori principle\n",
    "\n",
    "```\n",
    "If an itemset is frequent, all of its subsets are frequent\n",
    "```\n",
    "\n",
    "## Reverse of aprori principle\n",
    "```\n",
    "If an itemset is infrequent, then all of its supersets are infrequent\n",
    "```\n",
    "<img src=\"files/lat_itemsets.png\" style=\"width:400px; display:inline\">\n",
    "\n",
    "## Finding frequent itemsets\n",
    "```\n",
    "Calculate L1 as the frequent itemsets of length 1\n",
    "k = 2\n",
    "While L(k-1) is not empty\n",
    "    Generate the candidate set of length k from L(k-1)\n",
    "    Scan the candidate set to find frequent itemsets of length k \n",
    "    Lk are the frequent itemsets of length k\n",
    "    k = k + 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 - *-\n",
    "\n",
    "dict_products = {\n",
    "    1: 'tomate',\n",
    "    2: 'berenjena',\n",
    "    3: 'cerveza',\n",
    "    4: 'gamba', \n",
    "    5: 'donut',    \n",
    "}\n",
    "\n",
    "def load_dataset():\n",
    "    \"Load the sample dataset.\"\n",
    "    #return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
    "    return [[dict_products[1], dict_products[3], dict_products[4]], \n",
    "            [dict_products[2], dict_products[3], dict_products[5]], \n",
    "            [dict_products[1], dict_products[2], dict_products[3], dict_products[5]], \n",
    "            [dict_products[2], dict_products[5]]]\n",
    "\n",
    "\n",
    "def createC1(dataset):\n",
    "    \"Create a list of candidate item sets of size one.\"\n",
    "    c1 = []\n",
    "    for transaction in dataset:\n",
    "        for item in transaction:\n",
    "            if not [item] in c1:\n",
    "                c1.append([item])\n",
    "    c1.sort()\n",
    "    #frozenset because it will be a key of a dictionary.\n",
    "    return map(frozenset, c1)\n",
    "\n",
    "\n",
    "def scanD(dataset, candidates, min_support):\n",
    "    \"Returns all candidates that meets a minimum support level\"\n",
    "    sscnt = {}\n",
    "    for tid in dataset:\n",
    "        for can in candidates:\n",
    "            if can.issubset(tid):\n",
    "                sscnt.setdefault(can, 0)\n",
    "                sscnt[can] += 1\n",
    "\n",
    "    num_items = float(len(dataset))\n",
    "    retlist = []\n",
    "    support_data = {}\n",
    "    for key in sscnt:\n",
    "        support = sscnt[key] / num_items\n",
    "        if support >= min_support:\n",
    "            retlist.insert(0, key)\n",
    "        support_data[key] = support\n",
    "    return retlist, support_data\n",
    "\n",
    "\n",
    "def aprioriGen(freq_sets, k):\n",
    "    \"Generate the joint transactions from candidate sets\"\n",
    "    retList = []\n",
    "    lenLk = len(freq_sets)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "            L1 = list(freq_sets[i])[:k - 2]\n",
    "            L2 = list(freq_sets[j])[:k - 2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            if L1 == L2:\n",
    "                retList.append(freq_sets[i] | freq_sets[j])\n",
    "    return retList\n",
    "\n",
    "\n",
    "def apriori(dataset, minsupport=0.5):\n",
    "    \"Generate a list of candidate item sets\"\n",
    "    C1 = createC1(dataset)\n",
    "    D = map(set, dataset)\n",
    "    L1, support_data = scanD(D, C1, minsupport)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while (len(L[k - 2]) > 0):\n",
    "        Ck = aprioriGen(L[k - 2], k)\n",
    "        Lk, supK = scanD(D, Ck, minsupport)\n",
    "        support_data.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "\n",
    "    return L, support_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tomate', 'cerveza', 'gamba'],\n",
       " ['berenjena', 'cerveza', 'donut'],\n",
       " ['tomate', 'berenjena', 'cerveza', 'donut'],\n",
       " ['berenjena', 'donut']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({'berenjena'}),\n",
       " frozenset({'cerveza'}),\n",
       " frozenset({'donut'}),\n",
       " frozenset({'gamba'}),\n",
       " frozenset({'tomate'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = createC1(dataset)\n",
    "C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cerveza', 'gamba', 'tomate'},\n",
       " {'berenjena', 'cerveza', 'donut'},\n",
       " {'berenjena', 'cerveza', 'donut', 'tomate'},\n",
       " {'berenjena', 'donut'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = map(set, dataset)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets of length 1: [frozenset(['berenjena']), frozenset(['donut']), frozenset(['tomate']), frozenset(['cerveza'])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{frozenset({'gamba'}): 0.25,\n",
       " frozenset({'cerveza'}): 0.75,\n",
       " frozenset({'tomate'}): 0.5,\n",
       " frozenset({'berenjena'}): 0.75,\n",
       " frozenset({'donut'}): 0.75}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1, support_data = scanD(D, C1, 0.5)\n",
    "print(\"Frequent itemsets of length 1: {}\".format(L1))\n",
    "support_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({'berenjena', 'donut'}),\n",
       " frozenset({'berenjena', 'tomate'}),\n",
       " frozenset({'berenjena', 'cerveza'}),\n",
       " frozenset({'donut', 'tomate'}),\n",
       " frozenset({'cerveza', 'donut'}),\n",
       " frozenset({'cerveza', 'tomate'})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C2 = aprioriGen(L1,2)\n",
    "C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets of length 2: [frozenset(['donut', 'berenjena']), frozenset(['tomate', 'cerveza']), frozenset(['donut', 'cerveza']), frozenset(['cerveza', 'berenjena'])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{frozenset({'donut', 'tomate'}): 0.25,\n",
       " frozenset({'berenjena', 'cerveza'}): 0.5,\n",
       " frozenset({'cerveza', 'donut'}): 0.5,\n",
       " frozenset({'cerveza', 'tomate'}): 0.5,\n",
       " frozenset({'berenjena', 'donut'}): 0.75,\n",
       " frozenset({'berenjena', 'tomate'}): 0.25}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2, support_data2 = scanD(D, C2, 0.5)\n",
    "print(\"Frequent itemsets of length 2: {}\".format(L2))\n",
    "support_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[frozenset(['berenjena']), frozenset(['donut']), frozenset(['tomate']), frozenset(['cerveza'])], [frozenset(['donut', 'berenjena']), frozenset(['tomate', 'cerveza']), frozenset(['donut', 'cerveza']), frozenset(['cerveza', 'berenjena'])], [frozenset(['donut', 'cerveza', 'berenjena'])], []]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{frozenset({'tomate'}): 0.5,\n",
       " frozenset({'donut'}): 0.75,\n",
       " frozenset({'donut', 'tomate'}): 0.25,\n",
       " frozenset({'cerveza'}): 0.75,\n",
       " frozenset({'berenjena'}): 0.75,\n",
       " frozenset({'berenjena', 'cerveza'}): 0.5,\n",
       " frozenset({'cerveza', 'donut'}): 0.5,\n",
       " frozenset({'cerveza', 'tomate'}): 0.5,\n",
       " frozenset({'gamba'}): 0.25,\n",
       " frozenset({'berenjena', 'donut'}): 0.75,\n",
       " frozenset({'berenjena', 'cerveza', 'donut'}): 0.5,\n",
       " frozenset({'berenjena', 'tomate'}): 0.25}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L, supportdata = apriori(dataset, minsupport=0.5)\n",
    "print(L)\n",
    "supportdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining association rules from frequent item sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a way to calculate the frequent item sets, we can generate the association rules that fit the support and confidence requirements.\n",
    "\n",
    "## Apriori principle in association rules\n",
    "\n",
    "``` If the rule does not meet the minimum confidence requirement, then rules with the left hand side subset of that rule also will not meet the minimum. ```\n",
    "\n",
    "<img src=\"files/lat_rules.png\" style=\"width:400px; display:inline\">\n",
    "\n",
    "## Finding association rules\n",
    "\n",
    "```\n",
    "Calculate frequent itemsets\n",
    "rules = []\n",
    "For each frequent itemset\n",
    "    Create the list of rules with 1 item in the right hand side\n",
    "    Test the confidence of the rules and add the ones whose confidence is higher than the threshold\n",
    "    Generate the list of rules with 2 items in the right hand side\n",
    "    k = 2\n",
    "    While there are candidate rules with k items in the right hand side\n",
    "        Test the confidence of the rules and add the ones whose confidence is higher than the threshold\n",
    "        Generate the list of rules with the right hand side of length k + 1\n",
    "        k = k + 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateRules(L, support_data, min_confidence=0.7):\n",
    "    \"\"\"Create the association rules\n",
    "    L: list of frequent item sets\n",
    "    support_data: support data for those itemsets\n",
    "    min_confidence: minimum confidence threshold\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    for i in range(1, len(L)):\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            print \"freqSet\", freqSet, 'H1', H1\n",
    "            if (i > 1):\n",
    "                rules_from_conseq(freqSet, H1, support_data, rules, min_confidence)\n",
    "            else:\n",
    "                calc_confidence(freqSet, H1, support_data, rules, min_confidence)\n",
    "    return rules\n",
    "\n",
    "\n",
    "def calc_confidence(freqSet, H, support_data, rules, min_confidence=0.7):\n",
    "    \"Evaluate the rule generated\"\n",
    "    pruned_H = []\n",
    "    for conseq in H:\n",
    "        conf = support_data[freqSet] / support_data[freqSet - conseq]\n",
    "        if conf >= min_confidence:\n",
    "            print freqSet - conseq, '--->', conseq, 'conf:', conf\n",
    "            rules.append((freqSet - conseq, conseq, conf))\n",
    "            pruned_H.append(conseq)\n",
    "    return pruned_H\n",
    "\n",
    "def rules_from_conseq(freqSet, H, support_data, rules, min_confidence=0.7):\n",
    "    \"Generate a set of candidate rules\"\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)):\n",
    "        Hmp1 = aprioriGen(H, m + 1)\n",
    "        Hmp1 = calc_confidence(freqSet, Hmp1,  support_data, rules, min_confidence)\n",
    "        if len(Hmp1) > 1:\n",
    "            rules_from_conseq(freqSet, Hmp1, support_data, rules, min_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tomate', 'cerveza', 'gamba'],\n",
       " ['berenjena', 'cerveza', 'donut'],\n",
       " ['tomate', 'berenjena', 'cerveza', 'donut'],\n",
       " ['berenjena', 'donut']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[frozenset(['berenjena']), frozenset(['donut']), frozenset(['tomate']), frozenset(['cerveza'])], [frozenset(['donut', 'berenjena']), frozenset(['tomate', 'cerveza']), frozenset(['donut', 'cerveza']), frozenset(['cerveza', 'berenjena'])], [frozenset(['donut', 'cerveza', 'berenjena'])], []]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{frozenset({'tomate'}): 0.5,\n",
       " frozenset({'donut'}): 0.75,\n",
       " frozenset({'donut', 'tomate'}): 0.25,\n",
       " frozenset({'cerveza'}): 0.75,\n",
       " frozenset({'berenjena'}): 0.75,\n",
       " frozenset({'berenjena', 'cerveza'}): 0.5,\n",
       " frozenset({'cerveza', 'donut'}): 0.5,\n",
       " frozenset({'cerveza', 'tomate'}): 0.5,\n",
       " frozenset({'gamba'}): 0.25,\n",
       " frozenset({'berenjena', 'donut'}): 0.75,\n",
       " frozenset({'berenjena', 'cerveza', 'donut'}): 0.5,\n",
       " frozenset({'berenjena', 'tomate'}): 0.25}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L, supportdata = apriori(dataset, minsupport=0.5)\n",
    "print(L)\n",
    "supportdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqSet frozenset(['donut', 'berenjena']) H1 [frozenset(['donut']), frozenset(['berenjena'])]\n",
      "frozenset(['berenjena']) ---> frozenset(['donut']) conf: 1.0\n",
      "frozenset(['donut']) ---> frozenset(['berenjena']) conf: 1.0\n",
      "freqSet frozenset(['tomate', 'cerveza']) H1 [frozenset(['tomate']), frozenset(['cerveza'])]\n",
      "frozenset(['tomate']) ---> frozenset(['cerveza']) conf: 1.0\n",
      "freqSet frozenset(['donut', 'cerveza']) H1 [frozenset(['donut']), frozenset(['cerveza'])]\n",
      "freqSet frozenset(['cerveza', 'berenjena']) H1 [frozenset(['cerveza']), frozenset(['berenjena'])]\n",
      "freqSet frozenset(['donut', 'cerveza', 'berenjena']) H1 [frozenset(['donut']), frozenset(['cerveza']), frozenset(['berenjena'])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({'berenjena'}), frozenset({'donut'}), 1.0),\n",
       " (frozenset({'donut'}), frozenset({'berenjena'}), 1.0),\n",
       " (frozenset({'tomate'}), frozenset({'cerveza'}), 1.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = generateRules(L, supportdata, min_confidence=0.7)\n",
    "L\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
